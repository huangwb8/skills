# auto-test-skill

自动化测试驱动优化技能 - 用于AI辅助开发后的系统性测试和迭代优化。

## 概述

本技能提供了一套完整的测试驱动优化工作流,帮助用户在AI辅助开发后进行系统性的测试、问题修复和迭代优化。

**核心价值**:
- ✅ **结构化问题管理**: 从bug发现到优先级排序的全流程管理
- ✅ **可重复测试**: 规范化的测试目录和文档结构
- ✅ **渐进式优化**: 通过轻量测试快速验证修复效果
- ✅ **完整追溯**: 每轮迭代都有明确的测试计划和报告

**设计理念**:
本技能借鉴了成熟的软件测试实践(如时间戳命名测试会话、规范化文档结构、测试数据/脚本/输出分离等),确保每个测试会话都是独立、透明、可重复的。

## 适用场景

- ✅ 用户完成AI辅助开发后,需要进行系统性测试
- ✅ 发现bug需要记录和优先级排序
- ✅ 需要制定结构化的优化和测试计划
- ✅ 需要管理多轮迭代测试和修复流程
- ✅ 需要生成规范的测试报告和总结文档

## 使用方法

### 触发方式

在 Claude Code 中使用以下表述之一触发本技能:

- "帮我测试一下这个技能"
- "我需要制定测试计划"
- "帮我生成bug报告"
- "需要进行迭代优化"
- "生成测试报告"

### 输入要求

使用本技能前,请准备:

1. **目标技能的根目录路径**
   - 示例: `/path/to/skills/your-skill`

2. **测试发现的问题列表**
   - 可来自:用户反馈、测试结果、代码审查等
   - 至少包含:问题描述、复现步骤、期望行为

3. **可选**: 已有测试数据或测试用例
   - 如果有,请提供数据路径

### 工作流程

本技能遵循**6阶段工作流**:

```
阶段1: 问题收集与分析
  ↓
阶段2: 优化计划制定
  ↓
阶段3: 测试会话管理
  ↓
阶段4: 执行优化与测试
  ↓
阶段5: 测试报告与总结
  ↓
阶段6: 迭代循环或结束
```

详细说明请参阅 [SKILL.md](SKILL.md)。

## 输出交付

使用本技能后,您将获得:

1. **结构化的问题报告** (`BUG_REPORT.md`)
   - Bug详情(现象、根因、修复建议)
   - 优先级排序(P0/P1/P2/P3)
   - 验证方法和测试用例

2. **详细的优化计划** (`OPTIMIZATION_PLAN.md`)
   - Step-by-step修复步骤
   - 轻量测试计划(验证点、预期结果)
   - 时间估算和风险评估

3. **测试会话目录** (`test/v{YYYYMMDDHHMM}/`)
   - 规范化的目录结构
   - 包含:TEST_PLAN.md、TEST_REPORT.md等
   - 测试数据、脚本、输出分离

4. **最终测试总结** (`FINAL_SUMMARY.md`)
   - 修复历程回顾
   - 质量改进统计
   - 经验教训总结

## 文件结构

```
auto-test-skill/
├── SKILL.md                           # 技能主文档
├── README.md                          # 本文件
├── config.yaml                        # 配置文件
├── templates/                         # 文档模板
│   ├── BUG_REPORT_TEMPLATE.md         # Bug报告模板
│   ├── OPTIMIZATION_PLAN_TEMPLATE.md  # 优化计划模板
│   └── TEST_REPORT_TEMPLATE.md        # 测试报告模板
└── references/                        # 参考文档
    └── TESTING_BEST_PRACTICES.md      # 测试最佳实践(待创建)
```

## 配置说明

本技能使用 `config.yaml` 配置测试参数。

主要配置项:

- **test_session**: 测试会话配置(目录命名、最大迭代轮数)
- **priority**: 优先级定义(P0/P1/P2/P3的详细说明)
- **testing**: 测试配置(超时、失败处理、日志)
- **reporting**: 报告配置(格式、语言、图表)
- **quality**: 质量标准(覆盖率、通过率目标)
- **acceptance**: 验收标准(完成条件)

详细配置请参阅 [config.yaml](config.yaml)。

## 示例使用场景

### 场景 1: 修复技能的 Bug

**输入**:
- 用户报告某个技能的3个bug
- 技能根目录: `/path/to/skills/your-skill`

**执行流程**:
1. 阶段1: 生成 BUG_REPORT.md
2. 阶段2: 制定 OPTIMIZATION_PLAN.md(计划修复P0和P1问题)
3. 阶段3: 创建测试会话 `test/v202601021313/`
4. 阶段4: 执行修复,运行测试
5. 阶段5: 填写 TEST_REPORT.md
6. 阶段6: 验证通过,更新文档

**输出**:
- 修复后的代码
- 完整的测试文档
- CHANGELOG.md 更新

### 场景 2: 多轮迭代优化

**背景**: 第一次测试发现10个问题,计划分3轮迭代

**迭代轮次**:
- **第1轮** (`v202601021313`): 修复 P0(2个) + P1(3个) → 测试通过
- **第2轮** (`v202601031015`): 修复 P2(3个) → 测试通过
- **第3轮** (`v202601041420`): 修复 P3(2个) + 新发现的问题 → 测试通过

**最终输出**:
- FINAL_SUMMARY.md(总结3轮优化历程)
- 所有问题已修复
- 测试覆盖率提升

## 最佳实践

### 1. 问题分类原则

**严重程度判断标准**:

| 严重程度 | 判断问题 |
|----------|----------|
| **Critical** | 数据丢失、安全漏洞、完全无法使用 |
| **High** | 主要功能失效、性能严重退化、用户体验严重受损 |
| **Medium** | 边缘功能失效、性能轻微退化、用户体验一般受损 |
| **Low** | 文档错误、UI瑕疵、体验优化建议 |

### 2. 迭代计划原则

**每次迭代应该**:
- ✅ 专注修复少量高优先级问题(3-5个)
- ✅ 确保每个修复都有对应的测试
- ✅ 验证无回归后再合并

**每次迭代不应该**:
- ❌ 试图修复所有问题
- ❌ 修复没有测试的问题
- ❌ 引入新的破坏性变更

### 3. 测试设计原则

**好的测试用例**:
- ✅ 快速执行(几秒内)
- ✅ 独立运行(不依赖顺序)
- ✅ 结果明确(通过/失败清晰)
- ✅ 可重复执行(结果稳定)

**测试用例模板**:
```python
def test_fix_problem_1():
    """测试问题#1的修复效果"""
    # Arrange
    input_data = {...}

    # Act
    result = function_to_test(input_data)

    # Assert
    assert result == expected_output
```

### 4. 文档管理原则

**测试文档应该**:
- ✅ 简洁明了(重点信息突出)
- ✅ 结构一致(使用统一模板)
- ✅ 及时更新(每个阶段结束后立即更新)
- ✅ 独立完整(不依赖外部文档)

## 常见问题

### Q1: 如果测试会话太多怎么办?

**A**: 测试会话目录本身就很轻量(主要是文档),可以保留所有历史会话。如果需要清理,建议:
- 保留最近10个会话
- 归档早期的会话到 `test_archive/`
- 保留关键里程碑的会话(如首次完整测试、重大修复等)

### Q2: 如果一个问题需要多轮迭代才能修复怎么办?

**A**:
- 在第一轮迭代中,尝试最小化修复(缓解问题而非完美解决)
- 在后续迭代中,逐步完善修复
- 在 BUG_REPORT.md 中标记问题的演进历史

### Q3: 如果在修复过程中引入新问题怎么办?

**A**:
- 立即记录新问题到 BUG_REPORT.md
- 评估新问题的严重程度
- 如果是 P0/P1,停止当前修复,优先处理新问题
- 如果是 P2/P3,记录到下次迭代计划

### Q4: 如何确保测试的轻量级?

**A**:
- 优先使用单元测试而非集成测试
- 使用 mock/stub 隔离外部依赖
- 测试数据尽量小而精
- 避免耗时操作(如网络请求、文件IO)

## 参考资源

- **技能主文档**: [SKILL.md](SKILL.md)
- **配置文件**: [config.yaml](config.yaml)
- **文档模板**: [templates/](templates/)
- **Agent Skills标准**: [https://agentskills.io](https://agentskills.io)

**相关阅读**:
- 测试驱动开发(TDD)最佳实践
- 敏捷开发中的迭代优化方法
- 软件质量保证(SQA)标准流程

## WHICHMODEL - 模型选择最佳实践

本节由 `which-model` skill 自动调研生成，最后更新：2026-01-03

### 场景一：代码分析与 Bug 检测
- **推荐模型**：Claude Sonnet 4.5
- **推荐参数**：
  - 推理强度：medium
  - Thinking 模式：开
  - Temperature：0.3（平衡准确性与创造性）
  - Max Tokens：8192
- **理由**：Sonnet 4.5 在 SWE-bench Verified 上达到 state-of-the-art 性能，比 GPT-4o 高出约 25% 在代码分析任务上。特别适合静态代码分析和漏洞检测。[来源：Claude Sonnet 4.5 - Anthropic 官方 - Sonnet 在代码测试和分析上的性能提升]

### 场景二：测试用例生成
- **推荐模型**：Claude Sonnet 4.5
- **推荐参数**：
  - 推理强度：medium
  - Thinking 模式：开
  - Temperature：0.5（允许一定的测试场景多样性）
  - Max Tokens：4096
- **理由**：测试用例生成需要理解代码逻辑并设计边界条件，Sonnet 4.5 在代码理解和推理上表现优异，且支持 up to 64K output tokens 适合生成大量测试代码。[来源：Claude Sonnet 4.5 Technical Analysis - Sonnet 的长文本生成能力]

### 场景三：测试计划与优化方案制定
- **推荐模型**：Claude Opus 4.5
- **推荐参数**：
  - 推理强度：high
  - Thinking 模式：开
  - Temperature：0.7（鼓励多角度思考）
  - Max Tokens：16384
- **理由**：制定优化计划需要综合考虑多个因素（优先级、依赖关系、风险评估），Opus 4.5 的最强推理能力能确保计划的完整性和可执行性。[来源：Claude Code Best Practices - 复杂规划任务使用 Opus]

### 场景四：快速代码审查（轻量级）
- **推荐模型**：Claude Haiku 4.5
- **推荐参数**：
  - 推理强度：low
  - Thinking 模式：关
  - Temperature：0.3
  - Max Tokens：2048
- **理由**：对于简单的代码风格检查或基础问题识别，Haiku 4.5 能提供快速反馈，适合早期快速筛查。[来源：Choosing the right model - 从 Haiku 开始的渐进式策略]

### 通用原则
1. **代码分析用 Sonnet**：Sonnet 4.5 是代码分析和漏洞检测的最佳选择（SWE-bench Verified 领先）
2. **复杂规划用 Opus**：多轮迭代优化计划、复杂依赖关系分析需要 Opus 4.5 的最强推理
3. **快速筛查用 Haiku**：简单的风格检查或早期问题识别可用 Haiku 4.5 节省时间
4. **测试生成用 Sonnet**：Sonnet 4.5 支持长文本输出（64K tokens），适合生成大量测试代码
5. **Temperature 调整**：漏洞检测用低 Temperature（0.1-0.3），规划用中高 Temperature（0.5-0.7）

### 更新记录
- 2026-01-03：初始调研，基于 Anthropic 官方文档、SWE-bench Verified 基准测试和软件工程最佳实践

## 版本历史

- **v1.0.0** (2026-01-02): 初始版本
  - 6阶段工作流
  - 结构化问题管理
  - 测试会话管理
  - 文档模板系统

## 许可证

本技能遵循 [Agent Skills 开放标准](https://agentskills.io)。

## 联系方式

- **作者**: bensz
- **创建时间**: 2026-01-02
- **反馈渠道**: 通过 GitHub Issues 或项目讨论区反馈

---

**祝您测试愉快!** 🎉
