#!/usr/bin/env python3
"""
Project Init Generator - ç”Ÿæˆè„šæœ¬

ç”¨äºç”Ÿæˆ AI é¡¹ç›®æŒ‡ä»¤æ–‡ä»¶ï¼š
- CLAUDE.mdï¼ˆClaude Code é¡¹ç›®æŒ‡ä»¤ - ä¸»æ–‡ä»¶ï¼‰
- AGENTS.mdï¼ˆOpenAI Codex CLI é¡¹ç›®æŒ‡ä»¤ - åŸºäº CLAUDE.md é€‚é…ï¼‰
- README.mdï¼ˆé¡¹ç›®ä»‹ç»ä¸ä½¿ç”¨æ–¹æ³• - å¯é€‰ï¼‰
- CHANGELOG.mdï¼ˆAI ä¼˜åŒ–å†å²è®°å½• - å¯é€‰ï¼‰

æ”¯æŒè¯­è¨€æ£€æµ‹ã€æ¨¡æ¿å˜é‡æ›¿æ¢ã€è‡ªå®šä¹‰é…ç½®å’Œè‡ªåŠ¨é¡¹ç›®åˆ†æã€‚
"""

import os
import sys
import platform
import subprocess
import yaml
import re
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Tuple, Optional


class ProjectAnalyzer:
    """é¡¹ç›®ç»“æ„åˆ†æå™¨"""

    # é¡¹ç›®ç±»å‹è¯†åˆ«è§„åˆ™
    PROJECT_PATTERNS = {
        "python": {
            "indicators": ["pyproject.toml", "requirements.txt", "setup.py", "setup.cfg", "__init__.py"],
            "default_dirs": ["src/", "tests/", "docs/", "notebooks/", "scripts/"],
            "name": "Python é¡¹ç›®"
        },
        "web": {
            "indicators": ["package.json", "yarn.lock", "pnpm-lock.yaml", "webpack.config.js"],
            "default_dirs": ["src/", "public/", "tests/", "docs/", "config/"],
            "name": "Web é¡¹ç›®"
        },
        "rust": {
            "indicators": ["Cargo.toml", "Cargo.lock"],
            "default_dirs": ["src/", "tests/", "benches/", "examples/"],
            "name": "Rust é¡¹ç›®"
        },
        "go": {
            "indicators": ["go.mod", "go.sum"],
            "default_dirs": ["cmd/", "pkg/", "internal/", "api/"],
            "name": "Go é¡¹ç›®"
        },
        "java": {
            "indicators": ["pom.xml", "build.gradle", "build.gradle.kts"],
            "default_dirs": ["src/main/", "src/test/", "docs/"],
            "name": "Java é¡¹ç›®"
        },
        "data-science": {
            "indicators": ["*.ipynb", "*.R", "requirements.txt", "environment.yml"],
            "default_dirs": ["data/", "notebooks/", "src/", "models/", "reports/"],
            "name": "æ•°æ®ç§‘å­¦é¡¹ç›®"
        },
        "docs": {
            "indicators": ["*.md", "docs/", "_docs/", "mkdocs.yml", "docusaurus.config.js"],
            "default_dirs": ["docs/", "assets/", "static/"],
            "name": "æ–‡æ¡£é¡¹ç›®"
        },
    }

    @classmethod
    def analyze_project(cls, root_dir: Path) -> Dict:
        """
        åˆ†æé¡¹ç›®ç›®å½•ç»“æ„ï¼Œæ¨æ–­é¡¹ç›®ç±»å‹å’Œç”¨é€”

        Args:
            root_dir: é¡¹ç›®æ ¹ç›®å½•

        Returns:
            åŒ…å«é¡¹ç›®ä¿¡æ¯çš„å­—å…¸
        """
        result = {
            "name": None,
            "type": "é€šç”¨",
            "description": None,
            "directory_tree": None,
            "detected_dirs": [],
        }

        # 1. å°è¯•ä» README è·å–é¡¹ç›®åç§°å’Œæè¿°
        readme_files = ["README.md", "README.txt", "README.rst", "readme.md"]
        for readme_name in readme_files:
            readme_path = root_dir / readme_name
            if readme_path.exists():
                name, desc = cls._parse_readme(readme_path)
                if name:
                    result["name"] = name
                if desc:
                    result["description"] = desc
                break

        # 2. ä»ç›®å½•åæ¨æ–­é¡¹ç›®åç§°
        if not result["name"]:
            result["name"] = cls._sanitize_name(root_dir.name)

        # 3. æ£€æµ‹é¡¹ç›®ç±»å‹
        project_type, type_info = cls._detect_project_type(root_dir)
        result["type"] = project_type
        result["type_info"] = type_info

        # 4. ç”Ÿæˆç›®å½•æ ‘
        result["directory_tree"] = cls._generate_tree(root_dir, max_depth=2)

        return result

    @classmethod
    def _parse_readme(cls, readme_path: Path) -> Tuple[Optional[str], Optional[str]]:
        """
        è§£æ README æ–‡ä»¶ï¼Œæå–é¡¹ç›®åç§°å’Œæè¿°

        Returns:
            (é¡¹ç›®åç§°, é¡¹ç›®æè¿°)
        """
        try:
            with open(readme_path, 'r', encoding='utf-8') as f:
                content = f.read()

            # æå–æ ‡é¢˜ï¼ˆ# æ ‡é¢˜ï¼‰
            title_match = re.search(r'^#\s+(.+)$', content, re.MULTILINE)
            name = title_match.group(1).strip() if title_match else None

            # æå–ç¬¬ä¸€æ®µä½œä¸ºæè¿°
            paragraphs = re.split(r'\n\n+', content)
            desc = None
            for para in paragraphs:
                # è·³è¿‡æ ‡é¢˜
                if para.startswith('#'):
                    continue
                # è·å–ç¬¬ä¸€ä¸ªéç©ºæ®µè½
                clean_para = para.strip()
                if clean_para and len(clean_para) > 10:
                    desc = clean_para[:200]  # é™åˆ¶é•¿åº¦
                    break

            return name, desc
        except Exception:
            return None, None

    @classmethod
    def _detect_project_type(cls, root_dir: Path) -> Tuple[str, Dict]:
        """
        æ£€æµ‹é¡¹ç›®ç±»å‹

        Returns:
            (ç±»å‹é”®å, ç±»å‹ä¿¡æ¯å­—å…¸)
        """
        all_files = []
        all_dirs = []

        # æ”¶é›†æ‰€æœ‰æ–‡ä»¶å’Œç›®å½•
        for item in root_dir.iterdir():
            if item.is_file() and not item.name.startswith('.'):
                all_files.append(item.name)
            elif item.is_dir() and not item.name.startswith('.'):
                all_dirs.append(item.name)

        # æ£€æŸ¥æ¯ç§é¡¹ç›®ç±»å‹
        for type_key, type_info in cls.PROJECT_PATTERNS.items():
            for indicator in type_info["indicators"]:
                # æ£€æŸ¥æ–‡ä»¶ï¼ˆæ”¯æŒé€šé…ç¬¦ï¼‰
                if '*' in indicator:
                    pattern = indicator.replace('*', '.*')
                    if any(re.match(pattern, f) for f in all_files):
                        return type_key, type_info
                # æ£€æŸ¥ç²¾ç¡®æ–‡ä»¶å
                elif indicator in all_files:
                    return type_key, type_info
                # æ£€æŸ¥ç›®å½•
                elif indicator.endswith('/') and indicator[:-1] in all_dirs:
                    return type_key, type_info

        # é»˜è®¤è¿”å›é€šç”¨ç±»å‹
        return "generic", {
            "name": "é€šç”¨é¡¹ç›®",
            "default_dirs": ["src/", "docs/", "tests/"]
        }

    @classmethod
    def _generate_tree(cls, root_dir: Path, max_depth: int = 2) -> str:
        """
        ç”Ÿæˆç›®å½•æ ‘å­—ç¬¦ä¸²

        Args:
            root_dir: æ ¹ç›®å½•
            max_depth: æœ€å¤§æ·±åº¦

        Returns:
            ç›®å½•æ ‘å­—ç¬¦ä¸²
        """
        lines = []
        ignore = {'.git', '.DS_Store', '__pycache__', 'node_modules', '.venv', 'venv', '.env', 'dist', 'build'}

        def _add_tree(path: Path, prefix: str, depth: int):
            if depth > max_depth:
                return

            try:
                items = sorted(path.iterdir(), key=lambda x: (not x.is_dir(), x.name))
            except PermissionError:
                return

            # è¿‡æ»¤å¿½ç•¥é¡¹
            items = [i for i in items if i.name not in ignore and not i.name.startswith('.')]

            for i, item in enumerate(items):
                is_last = i == len(items) - 1
                connector = "â””â”€â”€ " if is_last else "â”œâ”€â”€ "
                lines.append(f"{prefix}{connector}{item.name}")

                if item.is_dir() and depth < max_depth:
                    extension = "    " if is_last else "â”‚   "
                    _add_tree(item, prefix + extension, depth + 1)

        lines.append(root_dir.name + "/")
        _add_tree(root_dir, "", 0)

        return "\n".join(lines)

    @classmethod
    def _sanitize_name(cls, name: str) -> str:
        """æ¸…ç†é¡¹ç›®åç§°"""
        # ç§»é™¤ç‰¹æ®Šå­—ç¬¦ï¼Œæ›¿æ¢ç©ºæ ¼å’Œè¿å­—ç¬¦
        clean = re.sub(r'[^\w\s-]', '', name)
        clean = re.sub(r'[-\s]+', '-', clean)
        return clean.strip("-")


class ProjectInitGenerator:
    """é¡¹ç›®åˆå§‹åŒ–æ–‡æ¡£ç”Ÿæˆå™¨"""

    def __init__(self, config_path: str = None):
        """
        åˆå§‹åŒ–ç”Ÿæˆå™¨

        Args:
            config_path: é…ç½®æ–‡ä»¶è·¯å¾„ï¼ˆé»˜è®¤ä½¿ç”¨é¡¹ç›®å†… config.yamlï¼‰
        """
        # è·å–è„šæœ¬æ‰€åœ¨ç›®å½•
        script_dir = Path(__file__).parent.parent
        self.config_path = config_path or script_dir / "config.yaml"
        self.template_dir = script_dir / "templates"

        # åŠ è½½é…ç½®
        with open(self.config_path, 'r', encoding='utf-8') as f:
            self.config = yaml.safe_load(f)

    def detect_language(self) -> str:
        """
        æ£€æµ‹æ“ä½œç³»ç»Ÿé»˜è®¤è¯­è¨€

        Returns:
            è¯­è¨€æè¿°ï¼ˆå¦‚ï¼šç®€ä½“ä¸­æ–‡ã€Englishï¼‰
        """
        system = platform.system().lower()
        lang_code = None

        # æ ¹æ®ç³»ç»Ÿé€‰æ‹©æ£€æµ‹å‘½ä»¤
        commands = self.config.get('language_detection_commands', {}).get(system, [])
        if not commands:
            commands = ["echo $LANG"]

        for cmd in commands:
            try:
                result = subprocess.run(
                    cmd,
                    shell=True,
                    capture_output=True,
                    text=True,
                    timeout=5
                )
                if result.returncode == 0 and result.stdout.strip():
                    # æå–è¯­è¨€ä»£ç 
                    output = result.stdout.strip()
                    if "=" in output:
                        lang_code = output.split("=")[1].split(".")[0]
                    else:
                        lang_code = output.split()[0].split(".")[0]
                    break
            except (subprocess.TimeoutExpired, FileNotFoundError, Exception):
                continue

        # æ˜ å°„åˆ°å¯¹è¯è¯­è¨€
        mapping = self.config.get('language_mapping', {})
        return mapping.get(lang_code, mapping.get('default', 'ç®€ä½“ä¸­æ–‡'))

    def load_template(self, template_name: str) -> str:
        """
        åŠ è½½æ¨¡æ¿æ–‡ä»¶

        Args:
            template_name: æ¨¡æ¿æ–‡ä»¶åï¼ˆå¦‚ AGENTS.md.templateï¼‰

        Returns:
            æ¨¡æ¿å†…å®¹
        """
        template_path = self.template_dir / template_name
        with open(template_path, 'r', encoding='utf-8') as f:
            return f.read()

    def replace_placeholders(self, template: str, variables: dict) -> str:
        """
        æ›¿æ¢æ¨¡æ¿ä¸­çš„å ä½ç¬¦

        Args:
            template: æ¨¡æ¿å†…å®¹
            variables: å˜é‡å­—å…¸

        Returns:
            æ›¿æ¢åçš„å†…å®¹
        """
        result = template
        for key, value in variables.items():
            placeholder = "{" + key + "}"
            result = result.replace(placeholder, value or f"[å¾…å¡«å†™: {key}]")
        return result

    def generate_agents_md(self, variables: dict) -> str:
        """
        ç”Ÿæˆ AGENTS.md å†…å®¹

        Args:
            variables: æ¨¡æ¿å˜é‡å­—å…¸

        Returns:
            AGENTS.md å†…å®¹
        """
        template = self.load_template("AGENTS.md.template")
        return self.replace_placeholders(template, variables)

    def generate_claude_md(self, variables: dict) -> str:
        """
        ç”Ÿæˆ CLAUDE.md å†…å®¹

        Args:
            variables: æ¨¡æ¿å˜é‡å­—å…¸

        Returns:
            CLAUDE.md å†…å®¹
        """
        template = self.load_template("CLAUDE.md.template")
        return self.replace_placeholders(template, variables)

    def generate_readme_md(self, variables: dict) -> str:
        """
        ç”Ÿæˆ README.md å†…å®¹

        Args:
            variables: æ¨¡æ¿å˜é‡å­—å…¸

        Returns:
            README.md å†…å®¹
        """
        template = self.load_template("README.md.template")
        return self.replace_placeholders(template, variables)

    def generate_changelog_md(self, variables: dict) -> str:
        """
        ç”Ÿæˆ CHANGELOG.md å†…å®¹

        Args:
            variables: æ¨¡æ¿å˜é‡å­—å…¸

        Returns:
            CHANGELOG.md å†…å®¹
        """
        template = self.load_template("CHANGELOG.md.template")
        return self.replace_placeholders(template, variables)

    def append_changelog_entry(self, changelog_path: Path, entry: str) -> bool:
        """
        å‘ CHANGELOG.md è¿½åŠ æ–°æ¡ç›®

        Args:
            changelog_path: CHANGELOG.md æ–‡ä»¶è·¯å¾„
            entry: è¦è¿½åŠ çš„æ¡ç›®å†…å®¹

        Returns:
            æ˜¯å¦æˆåŠŸ
        """
        try:
            with open(changelog_path, 'r', encoding='utf-8') as f:
                content = f.read()

            # åœ¨ [Unreleased] éƒ¨åˆ†åé¢è¿½åŠ 
            if "## [Unreleased]" in content:
                parts = content.split("## [Unreleased]")
                new_content = parts[0] + "## [Unreleased]\n\n" + entry + "\n" + parts[1]
            else:
                # å¦‚æœæ²¡æœ‰ Unreleased éƒ¨åˆ†ï¼Œåœ¨æ–‡ä»¶æœ«å°¾è¿½åŠ 
                new_content = content + "\n" + entry

            with open(changelog_path, 'w', encoding='utf-8') as f:
                f.write(new_content)
            return True
        except Exception as e:
            print(f"âš ï¸  è¿½åŠ  CHANGELOG æ¡ç›®å¤±è´¥: {e}")
            return False

    def write_file(self, path: Path, content: str, overwrite: bool = False, merge: bool = False) -> bool:
        """
        å†™å…¥æ–‡ä»¶

        Args:
            path: æ–‡ä»¶è·¯å¾„
            content: æ–‡ä»¶å†…å®¹
            overwrite: æ˜¯å¦è¦†ç›–å·²å­˜åœ¨çš„æ–‡ä»¶
            merge: æ˜¯å¦æ™ºèƒ½åˆå¹¶å·²å­˜åœ¨çš„æ–‡ä»¶ï¼ˆä»…ç”¨äº CLAUDE.md å’Œ AGENTS.mdï¼‰

        Returns:
            æ˜¯å¦æˆåŠŸå†™å…¥
        """
        if path.exists() and not overwrite:
            if merge:
                # æ™ºèƒ½åˆå¹¶æ¨¡å¼ï¼šä¿ç•™ç”¨æˆ·è‡ªå®šä¹‰å†…å®¹ï¼Œæ›´æ–°æ ‡å‡†æ¨¡æ¿ç»“æ„
                content = self.merge_existing_file(path, content, path.name)
            else:
                return False

        path.parent.mkdir(parents=True, exist_ok=True)
        with open(path, 'w', encoding='utf-8') as f:
            f.write(content)
        return True

    def merge_existing_file(self, existing_path: Path, new_content: str, file_type: str) -> str:
        """
        æ™ºèƒ½åˆå¹¶ç°æœ‰æ–‡ä»¶å’Œæ–°å†…å®¹

        ç­–ç•¥ï¼š
        1. è¯»å–ç°æœ‰æ–‡ä»¶ï¼Œè¯†åˆ«ç”¨æˆ·è‡ªå®šä¹‰çš„ç« èŠ‚
        2. ä¿ç•™ä»¥ä¸‹ç”¨æˆ·è‡ªå®šä¹‰ç« èŠ‚ï¼ˆå¦‚æœå­˜åœ¨ï¼‰ï¼š
           - ## é¡¹ç›®ç›®æ ‡ ä¸‹çš„è‡ªå®šä¹‰æè¿°
           - ## æ ¸å¿ƒå·¥ä½œæµ ä¸‹çš„è‡ªå®šä¹‰å·¥ä½œæµ
           - ## å˜æ›´è¾¹ç•Œ ä¸‹çš„è‡ªå®šä¹‰è§„åˆ™
           - ç”¨æˆ·æ·»åŠ çš„è‡ªå®šä¹‰ç« èŠ‚ï¼ˆä¸åœ¨æ ‡å‡†æ¨¡æ¿ä¸­çš„ç« èŠ‚ï¼‰
        3. æ›´æ–°æ ‡å‡†åŒ–ç« èŠ‚ï¼š
           - ## å·¥ç¨‹åŸåˆ™ï¼ˆæ›´æ–°ä¸ºæœ€æ–°æ ‡å‡†ï¼‰
           - ## é»˜è®¤è¯­è¨€ï¼ˆæ›´æ–°ä¸ºæ£€æµ‹å€¼ï¼‰
           - ## ç›®å½•ç»“æ„ï¼ˆæ›´æ–°ä¸ºæœ€æ–°ç›®å½•æ ‘ï¼‰
           - å¹³å°ç‰¹å®šè¯´æ˜ï¼ˆClaude Code / Codex CLI ç‰¹å®šéƒ¨åˆ†ï¼‰

        Args:
            existing_path: ç°æœ‰æ–‡ä»¶è·¯å¾„
            new_content: æ–°ç”Ÿæˆçš„å†…å®¹
            file_type: æ–‡ä»¶ç±»å‹ï¼ˆ"CLAUDE.md" æˆ– "AGENTS.md"ï¼‰

        Returns:
            åˆå¹¶åçš„å†…å®¹
        """
        try:
            with open(existing_path, 'r', encoding='utf-8') as f:
                existing_content = f.read()
        except Exception:
            # å¦‚æœè¯»å–å¤±è´¥ï¼Œè¿”å›æ–°å†…å®¹
            return new_content

        # è§£æç°æœ‰æ–‡ä»¶ï¼Œæå–éœ€è¦ä¿ç•™çš„è‡ªå®šä¹‰å†…å®¹
        preserved_sections = {}
        custom_sections = []

        # 1. æå–éœ€è¦ä¿ç•™çš„è‡ªå®šä¹‰ç« èŠ‚
        section_patterns = {
            "é¡¹ç›®ç›®æ ‡": r"## é¡¹ç›®ç›®æ ‡\s*\n+(.*?)(?=\n##|\Z)",
            "æ ¸å¿ƒå·¥ä½œæµ": r"## æ ¸å¿ƒå·¥ä½œæµ\s*\n+(.*?)(?=\n##|\Z)",
            "å˜æ›´è¾¹ç•Œ": r"## å˜æ›´è¾¹ç•Œ\s*\n+(.*?)(?=\n##|\Z)",
        }

        for section_name, pattern in section_patterns.items():
            match = re.search(pattern, existing_content, re.DOTALL)
            if match:
                section_content = match.group(1).strip()
                # æ£€æŸ¥æ˜¯å¦æ˜¯é»˜è®¤æ¨¡æ¿å†…å®¹ï¼ˆé€šè¿‡ç‰¹å¾åˆ¤æ–­ï¼‰
                default_indicators = ["å¾…å¡«å†™", "è¯·æ ¹æ®å®é™…æƒ…å†µ", "[é¡¹ç›®ç±»å‹]", "[å¾…è¡¥å……"]
                if not any(indicator in section_content for indicator in default_indicators):
                    # è¿™æ˜¯ç”¨æˆ·è‡ªå®šä¹‰çš„å†…å®¹ï¼Œä¿ç•™å®ƒ
                    preserved_sections[section_name] = section_content

        # 2. æå–ç”¨æˆ·æ·»åŠ çš„è‡ªå®šä¹‰ç« èŠ‚ï¼ˆä¸åœ¨æ ‡å‡†æ¨¡æ¿ä¸­çš„ï¼‰
        standard_sections = {
            "CLAUDE.md": ["é¡¹ç›®ç›®æ ‡", "æ ¸å¿ƒå·¥ä½œæµ", "å·¥ç¨‹åŸåˆ™", "é»˜è®¤è¯­è¨€", "ç›®å½•ç»“æ„",
                         "Claude Code ç‰¹å®šè¯´æ˜", "æ–‡ä»¶å¼•ç”¨è§„èŒƒ", "éªŒè¯è¦ç‚¹", "å˜æ›´è¾¹ç•Œ",
                         "æœ‰æœºæ›´æ–°åŸåˆ™"],
            "AGENTS.md": ["é¡¹ç›®ç›®æ ‡", "æ ¸å¿ƒå·¥ä½œæµ", "å·¥ç¨‹åŸåˆ™", "é»˜è®¤è¯­è¨€", "ç›®å½•ç»“æ„",
                        "Codex CLI ç‰¹å®šè¯´æ˜", "æ–‡ä»¶å¼•ç”¨è§„èŒƒ", "éªŒè¯è¦ç‚¹", "å˜æ›´è¾¹ç•Œ",
                        "ä¸ CLAUDE.md çš„å…³ç³»", "æœ‰æœºæ›´æ–°åŸåˆ™"]
        }

        # æ‰¾å‡ºæ‰€æœ‰ç« èŠ‚æ ‡é¢˜
        all_sections = re.findall(r"^##\s+(.+)$", existing_content, re.MULTILINE)
        for section in all_sections:
            if section not in standard_sections.get(file_type, []):
                # è¿™æ˜¯ä¸€ä¸ªè‡ªå®šä¹‰ç« èŠ‚ï¼Œæå–å®ƒçš„å†…å®¹
                pattern = rf"## {re.escape(section)}\s*\n+(.*?)(?=\n##|\Z)"
                match = re.search(pattern, existing_content, re.DOTALL)
                if match:
                    custom_sections.append((section, match.group(1).strip()))

        # 3. åœ¨æ–°å†…å®¹ä¸­åº”ç”¨ä¿ç•™çš„è‡ªå®šä¹‰å†…å®¹
        merged_content = new_content

        # æ›¿æ¢ä¿ç•™çš„ç« èŠ‚
        for section_name, section_content in preserved_sections.items():
            pattern = rf"(## {re.escape(section_name)}\s*\n+)(.*?)(?=\n##|\Z)"
            merged_content = re.sub(pattern, rf"\1{section_content}\n", merged_content, count=1, flags=re.DOTALL)

        # æ·»åŠ è‡ªå®šä¹‰ç« èŠ‚åˆ°æ–‡ä»¶æœ«å°¾ï¼ˆåœ¨æœ‰æœºæ›´æ–°åŸåˆ™ä¹‹å‰ï¼‰
        if custom_sections:
            for section_name, section_content in custom_sections:
                # æ£€æŸ¥æ–°å†…å®¹ä¸­æ˜¯å¦å·²ç»æœ‰è¿™ä¸ªç« èŠ‚
                if f"## {section_name}" not in merged_content:
                    # åœ¨æœ‰æœºæ›´æ–°åŸåˆ™ä¹‹å‰æ’å…¥
                    merged_content = merged_content.replace(
                        "## æœ‰æœºæ›´æ–°åŸåˆ™",
                        f"## {section_name}\n\n{section_content}\n\n## æœ‰æœºæ›´æ–°åŸåˆ™"
                    )

        return merged_content

    # åŒæ­¥é…ç½®ï¼šæ ¸å¿ƒç« èŠ‚ï¼ˆéœ€è¦åœ¨æ‰€æœ‰æ–‡ä»¶ä¸­ä¿æŒä¸€è‡´ï¼‰
    CORE_SECTIONS = [
        "é¡¹ç›®ç›®æ ‡",
        "æ ¸å¿ƒå·¥ä½œæµ",
        "å·¥ç¨‹åŸåˆ™",
        "é»˜è®¤è¯­è¨€",
        "ç›®å½•ç»“æ„",
        "å˜æ›´è¾¹ç•Œ",
        "æœ‰æœºæ›´æ–°åŸåˆ™",
    ]

    # å¹³å°ç‰¹å®šç« èŠ‚ï¼ˆä¸åŒæ­¥ï¼‰
    PLATFORM_SPECIFIC_SECTIONS = {
        "CLAUDE.md": [
            "Claude Code ç‰¹å®šè¯´æ˜",
            "æ–‡ä»¶å¼•ç”¨è§„èŒƒ",
            "ä»»åŠ¡ç®¡ç†",
            "ä»£ç å˜æ›´è§„èŒƒ",
        ],
        "AGENTS.md": [
            "Codex CLI ç‰¹å®šè¯´æ˜",
            "æ–‡ä»¶å¼•ç”¨è§„èŒƒ",
            "ä»£ç ç¼–è¾‘è§„èŒƒ",
            "è¾“å‡ºæ ¼å¼",
        ],
    }

    def extract_section(self, content: str, section_name: str) -> Optional[str]:
        """
        ä»æ–‡ä»¶å†…å®¹ä¸­æå–æŒ‡å®šç« èŠ‚

        Args:
            content: æ–‡ä»¶å†…å®¹
            section_name: ç« èŠ‚åç§°

        Returns:
            ç« èŠ‚å†…å®¹ï¼ˆä¸åŒ…æ‹¬æ ‡é¢˜ï¼‰ï¼Œå¦‚æœæ‰¾ä¸åˆ°åˆ™è¿”å› None
        """
        pattern = rf"## {re.escape(section_name)}\s*\n+(.*?)(?=\n##|\Z)"
        match = re.search(pattern, content, re.DOTALL)
        return match.group(1).strip() if match else None

    def sync_from_source(self, source_path: Path, target_path: Path) -> bool:
        """
        ä»æºæ–‡ä»¶åŒæ­¥æ ¸å¿ƒç« èŠ‚åˆ°ç›®æ ‡æ–‡ä»¶

        ç­–ç•¥ï¼š
        1. è¯»å–æºæ–‡ä»¶ï¼Œæå–æ ¸å¿ƒç« èŠ‚
        2. è¯»å–ç›®æ ‡æ–‡ä»¶
        3. ä¿ç•™ç›®æ ‡æ–‡ä»¶çš„å¹³å°ç‰¹å®šç« èŠ‚
        4. ç”¨æºæ–‡ä»¶çš„æ ¸å¿ƒç« èŠ‚æ›¿æ¢ç›®æ ‡æ–‡ä»¶çš„å¯¹åº”ç« èŠ‚

        Args:
            source_path: æºæ–‡ä»¶è·¯å¾„ï¼ˆå¦‚ AGENTS.mdï¼‰
            target_path: ç›®æ ‡æ–‡ä»¶è·¯å¾„ï¼ˆå¦‚ CLAUDE.mdï¼‰

        Returns:
            æ˜¯å¦æˆåŠŸåŒæ­¥
        """
        if not source_path.exists():
            print(f"âŒ æºæ–‡ä»¶ä¸å­˜åœ¨: {source_path}")
            return False

        if not target_path.exists():
            print(f"âŒ ç›®æ ‡æ–‡ä»¶ä¸å­˜åœ¨: {target_path}")
            return False

        try:
            # è¯»å–æºæ–‡ä»¶å’Œç›®æ ‡æ–‡ä»¶
            with open(source_path, 'r', encoding='utf-8') as f:
                source_content = f.read()
            with open(target_path, 'r', encoding='utf-8') as f:
                target_content = f.read()

            # æå–æºæ–‡ä»¶çš„æ ¸å¿ƒç« èŠ‚
            source_sections = {}
            for section_name in self.CORE_SECTIONS:
                section_content = self.extract_section(source_content, section_name)
                if section_content:
                    source_sections[section_name] = section_content

            if not source_sections:
                print(f"âš ï¸  æºæ–‡ä»¶ä¸­æœªæ‰¾åˆ°ä»»ä½•æ ¸å¿ƒç« èŠ‚")
                return False

            # åŒæ­¥åˆ°ç›®æ ‡æ–‡ä»¶
            updated_content = target_content
            synced_sections = []

            for section_name, section_content in source_sections.items():
                # æ£€æŸ¥ç›®æ ‡æ–‡ä»¶ä¸­æ˜¯å¦æœ‰è¿™ä¸ªç« èŠ‚
                if f"## {section_name}" in updated_content:
                    # æ›¿æ¢ç°æœ‰ç« èŠ‚
                    pattern = rf"(## {re.escape(section_name)}\s*\n+)(.*?)(?=\n##|\Z)"
                    updated_content = re.sub(
                        pattern,
                        rf"\1{section_content}\n",
                        updated_content,
                        count=1,
                        flags=re.DOTALL
                    )
                    synced_sections.append(section_name)
                else:
                    # åœ¨"æœ‰æœºæ›´æ–°åŸåˆ™"ä¹‹å‰æ’å…¥æ–°ç« èŠ‚
                    updated_content = updated_content.replace(
                        "## æœ‰æœºæ›´æ–°åŸåˆ™",
                        f"## {section_name}\n\n{section_content}\n\n## æœ‰æœºæ›´æ–°åŸåˆ™"
                    )
                    synced_sections.append(section_name)

            # å†™å…¥ç›®æ ‡æ–‡ä»¶
            with open(target_path, 'w', encoding='utf-8') as f:
                f.write(updated_content)

            print(f"âœ… å·²ä» {source_path.name} åŒæ­¥åˆ° {target_path.name}")
            print(f"   åŒæ­¥çš„ç« èŠ‚: {', '.join(synced_sections)}")
            return True

        except Exception as e:
            print(f"âŒ åŒæ­¥å¤±è´¥: {e}")
            return False

    def check_consistency(self, claude_path: Path, agents_path: Path) -> dict:
        """
        æ£€æŸ¥ä¸¤ä¸ªæ–‡ä»¶çš„æ ¸å¿ƒç« èŠ‚æ˜¯å¦ä¸€è‡´

        Args:
            claude_path: CLAUDE.md æ–‡ä»¶è·¯å¾„
            agents_path: AGENTS.md æ–‡ä»¶è·¯å¾„

        Returns:
            {
                "consistent": bool,
                "diff_sections": ["é¡¹ç›®ç›®æ ‡", "æ ¸å¿ƒå·¥ä½œæµ"],
                "details": {ç« èŠ‚å: {"claude": "...", "agents": "..."}}
            }
        """
        result = {
            "consistent": True,
            "diff_sections": [],
            "details": {}
        }

        if not claude_path.exists() or not agents_path.exists():
            result["consistent"] = False
            result["error"] = "æ–‡ä»¶ä¸å­˜åœ¨"
            return result

        try:
            with open(claude_path, 'r', encoding='utf-8') as f:
                claude_content = f.read()
            with open(agents_path, 'r', encoding='utf-8') as f:
                agents_content = f.read()

            # æ£€æŸ¥æ¯ä¸ªæ ¸å¿ƒç« èŠ‚
            for section_name in self.CORE_SECTIONS:
                claude_section = self.extract_section(claude_content, section_name)
                agents_section = self.extract_section(agents_content, section_name)

                # å¦‚æœä¸¤ä¸ªæ–‡ä»¶éƒ½æœ‰è¿™ä¸ªç« èŠ‚ï¼Œæ¯”è¾ƒå†…å®¹
                if claude_section and agents_section:
                    # æ ‡å‡†åŒ–æ¯”è¾ƒï¼ˆç§»é™¤ç©ºç™½å·®å¼‚ï¼‰
                    claude_normalized = re.sub(r'\s+', ' ', claude_section.strip())
                    agents_normalized = re.sub(r'\s+', ' ', agents_section.strip())

                    if claude_normalized != agents_normalized:
                        result["consistent"] = False
                        result["diff_sections"].append(section_name)
                        result["details"][section_name] = {
                            "claude": claude_section[:100] + "..." if len(claude_section) > 100 else claude_section,
                            "agents": agents_section[:100] + "..." if len(agents_section) > 100 else agents_section
                        }
                # å¦‚æœåªæœ‰ä¸€ä¸ªæ–‡ä»¶æœ‰è¿™ä¸ªç« èŠ‚
                elif claude_section or agents_section:
                    result["consistent"] = False
                    result["diff_sections"].append(section_name)
                    result["details"][section_name] = {
                        "claude": claude_section or "(ä¸å­˜åœ¨)",
                        "agents": agents_section or "(ä¸å­˜åœ¨)"
                    }

        except Exception as e:
            result["consistent"] = False
            result["error"] = str(e)

        return result

    def check_consistency_reminder(self, claude_path: Path, agents_path: Path) -> None:
        """
        æ£€æŸ¥å¹¶æé†’ç”¨æˆ·ä¿æŒ CLAUDE.md å’Œ AGENTS.md çš„ä¸€è‡´æ€§

        Args:
            claude_path: CLAUDE.md æ–‡ä»¶è·¯å¾„
            agents_path: AGENTS.md æ–‡ä»¶è·¯å¾„
        """
        both_exist = claude_path.exists() and agents_path.exists()

        if both_exist:
            print("\n" + "="*60)
            print("ğŸ’¡ ä½¿ç”¨ init-project è„šæœ¬åŒæ­¥ CLAUDE.md å’Œ AGENTS.md")
            print("="*60)
            print("\nğŸ“‹ æ¨èå·¥ä½œæµï¼š")
            print("   1. å…ˆä¿®æ”¹ AGENTS.mdï¼ˆé¡¹ç›®æŒ‡ä»¤ä¸»æ–‡ä»¶ï¼‰")
            print("   2. è¿è¡ŒåŒæ­¥å‘½ä»¤ï¼š")
            print("      python3 init-project/scripts/generate.py --sync-from agents")
            print("   3. ï¼ˆå¯é€‰ï¼‰æ£€æŸ¥ä¸€è‡´æ€§ï¼š")
            print("      python3 init-project/scripts/generate.py --check-consistency")
            print("\nğŸ“Œ æ ¸å¿ƒç« èŠ‚å°†è‡ªåŠ¨åŒæ­¥ï¼š")
            print("   - é¡¹ç›®ç›®æ ‡ã€æ ¸å¿ƒå·¥ä½œæµã€å·¥ç¨‹åŸåˆ™")
            print("   - é»˜è®¤è¯­è¨€ã€ç›®å½•ç»“æ„ã€å˜æ›´è¾¹ç•Œã€æœ‰æœºæ›´æ–°åŸåˆ™")
            print("\nğŸ”§ å¹³å°ç‰¹å®šç« èŠ‚ä¿æŒç‹¬ç«‹ï¼š")
            print("   - Claude Code ç‰¹å®šè¯´æ˜ï¼ˆä»… CLAUDE.mdï¼‰")
            print("   - Codex CLI ç‰¹å®šè¯´æ˜ï¼ˆä»… AGENTS.mdï¼‰")
            print("="*60 + "\n")

    def generate_auto(
        self,
        output_dir: Path = None,
        overwrite: bool = False,
        skip_readme: bool = False,
        skip_changelog: bool = False,
        only_readme: bool = False,
        only_changelog: bool = False
    ) -> bool:
        """
        å®Œå…¨è‡ªåŠ¨ç”Ÿæˆï¼šåˆ†æå½“å‰ç›®å½•å¹¶ç”Ÿæˆæ–‡æ¡£

        Args:
            output_dir: è¾“å‡ºç›®å½•ï¼ˆé»˜è®¤å½“å‰ç›®å½•ï¼‰
            overwrite: æ˜¯å¦è¦†ç›–å·²å­˜åœ¨çš„æ–‡ä»¶
            skip_readme: è·³è¿‡ README.md ç”Ÿæˆ
            skip_changelog: è·³è¿‡ CHANGELOG.md ç”Ÿæˆ
            only_readme: ä»…ç”Ÿæˆ README.md
            only_changelog: ä»…ç”Ÿæˆ CHANGELOG.md

        Returns:
            æ˜¯å¦æˆåŠŸ
        """
        output_dir = output_dir or Path.cwd()

        # åˆ†æé¡¹ç›®
        analysis = ProjectAnalyzer.analyze_project(output_dir)

        # æ£€æµ‹è¯­è¨€
        language = self.detect_language()

        # å‡†å¤‡å˜é‡
        variables = self._prepare_variables(analysis, language, output_dir)

        success = True
        generated_files = []

        # å®šä¹‰æ–‡ä»¶è·¯å¾„
        claude_path = output_dir / "CLAUDE.md"
        agents_path = output_dir / "AGENTS.md"
        readme_path = output_dir / "README.md"
        changelog_path = output_dir / "CHANGELOG.md"

        # å¦‚æœæ˜¯ä»…ç”Ÿæˆç‰¹å®šæ–‡ä»¶æ¨¡å¼
        if only_readme:
            readme_content = self.generate_readme_md(variables)
            if self.write_file(readme_path, readme_content, overwrite):
                generated_files.append(readme_path)
            else:
                print(f"âš ï¸  {readme_path} å·²å­˜åœ¨ï¼Œä½¿ç”¨ --overwrite è¦†ç›–")
                success = False
        elif only_changelog:
            changelog_content = self.generate_changelog_md(variables)
            if self.write_file(changelog_path, changelog_content, overwrite):
                generated_files.append(changelog_path)
            else:
                print(f"âš ï¸  {changelog_path} å·²å­˜åœ¨ï¼Œä½¿ç”¨ --overwrite è¦†ç›–")
                success = False
        else:
            # å®Œæ•´ç”Ÿæˆæ¨¡å¼
            # 1. ç”Ÿæˆ CLAUDE.mdï¼ˆä¸»æŒ‡ä»¤æ–‡ä»¶ï¼‰- ä½¿ç”¨æ™ºèƒ½åˆå¹¶æ¨¡å¼
            claude_content = self.generate_claude_md(variables)
            claude_was_merged = claude_path.exists() and not overwrite
            if self.write_file(claude_path, claude_content, overwrite, merge=True):
                generated_files.append(claude_path)
                if claude_was_merged:
                    print(f"ğŸ”„ {claude_path} å·²æ™ºèƒ½æ›´æ–°ï¼ˆä¿ç•™äº†è‡ªå®šä¹‰å†…å®¹ï¼‰")
            else:
                print(f"âš ï¸  {claude_path} å·²å­˜åœ¨ï¼Œä½¿ç”¨ --overwrite è¦†ç›–")
                success = False

            # 2. ç”Ÿæˆ AGENTS.mdï¼ˆåŸºäº CLAUDE.md é€‚é…ï¼‰- ä½¿ç”¨æ™ºèƒ½åˆå¹¶æ¨¡å¼
            agents_content = self.generate_agents_md(variables)
            agents_was_merged = agents_path.exists() and not overwrite
            if self.write_file(agents_path, agents_content, overwrite, merge=True):
                generated_files.append(agents_path)
                if agents_was_merged:
                    print(f"ğŸ”„ {agents_path} å·²æ™ºèƒ½æ›´æ–°ï¼ˆä¿ç•™äº†è‡ªå®šä¹‰å†…å®¹ï¼‰")
            else:
                print(f"âš ï¸  {agents_path} å·²å­˜åœ¨ï¼Œä½¿ç”¨ --overwrite è¦†ç›–")
                success = False

            # æ˜¾ç¤ºä¸€è‡´æ€§æé†’
            self.check_consistency_reminder(claude_path, agents_path)

            # 3. ç”Ÿæˆ README.mdï¼ˆå¦‚æœä¸å­˜åœ¨æˆ–è¦æ±‚è¦†ç›–ï¼‰
            if not skip_readme:
                if not readme_path.exists() or overwrite:
                    readme_content = self.generate_readme_md(variables)
                    if self.write_file(readme_path, readme_content, overwrite):
                        generated_files.append(readme_path)
                else:
                    print(f"â„¹ï¸  {readme_path} å·²å­˜åœ¨ï¼Œè·³è¿‡ç”Ÿæˆï¼ˆä½¿ç”¨ --overwrite è¦†ç›–ï¼‰")

            # 4. ç”Ÿæˆæˆ–æ›´æ–° CHANGELOG.md
            if not skip_changelog:
                if not changelog_path.exists():
                    # åˆ›å»ºæ–°çš„ CHANGELOG.md
                    changelog_content = self.generate_changelog_md(variables)
                    if self.write_file(changelog_path, changelog_content, True):
                        generated_files.append(changelog_path)
                elif overwrite:
                    # å¦‚æœè¦æ±‚è¦†ç›–ï¼Œè¿½åŠ æ–°æ¡ç›®
                    today = datetime.now().strftime("%Y-%m-%d")
                    entry = f"""## [1.0.0] - {today}

### Addedï¼ˆæ–°å¢ï¼‰

- é‡æ–°åˆå§‹åŒ– AI é¡¹ç›®æŒ‡ä»¤æ–‡ä»¶
- æ›´æ–° `CLAUDE.md`ï¼ˆClaude Code é¡¹ç›®æŒ‡ä»¤ï¼‰
- æ›´æ–° `AGENTS.md`ï¼ˆOpenAI Codex CLI é¡¹ç›®æŒ‡ä»¤ï¼‰
"""
                    if self.append_changelog_entry(changelog_path, entry):
                        print(f"â„¹ï¸  å·²æ›´æ–° {changelog_path}")
                else:
                    print(f"â„¹ï¸  {changelog_path} å·²å­˜åœ¨ï¼Œè·³è¿‡æ›´æ–°")

        # è¾“å‡ºç»“æœ
        if generated_files:
            print(f"âœ… å·²ç”Ÿæˆ AI é¡¹ç›®æŒ‡ä»¤æ–‡æ¡£:")
            for f in generated_files:
                print(f"   - {f}")
            print(f"\nğŸ“Š é¡¹ç›®åˆ†æç»“æœ:")
            print(f"   åç§°: {analysis['name']}")
            print(f"   ç±»å‹: {analysis['type_info']['name']}")
            print(f"   è¯­è¨€: {language}")

        return success

    def _prepare_variables(self, analysis: dict, language: str, output_dir: Path) -> dict:
        """å‡†å¤‡æ¨¡æ¿å˜é‡"""
        project_type = analysis['type_info']['name']
        today = datetime.now().strftime("%Y-%m-%d")

        # æ ¹æ®é¡¹ç›®ç±»å‹ç”Ÿæˆé»˜è®¤å·¥ä½œæµæè¿°
        workflow_templates = {
            "Python é¡¹ç›®": "ä»£ç å¼€å‘ â†’ å•å…ƒæµ‹è¯• â†’ æ–‡æ¡£æ›´æ–° â†’ ç‰ˆæœ¬å‘å¸ƒ",
            "Web é¡¹ç›®": "åŠŸèƒ½å¼€å‘ â†’ ç»„ä»¶æµ‹è¯• â†’ æ„å»ºéƒ¨ç½² â†’ ç›‘æ§åé¦ˆ",
            "æ•°æ®ç§‘å­¦é¡¹ç›®": "æ•°æ®è·å– â†’ æ¢ç´¢åˆ†æ â†’ æ¨¡å‹è®­ç»ƒ â†’ éªŒè¯è¯„ä¼°",
            "Rust é¡¹ç›®": "API è®¾è®¡ â†’ å®ç° â†’ å•å…ƒæµ‹è¯• â†’ æ–‡æ¡£ â†’ å‘å¸ƒ",
            "Go é¡¹ç›®": "éœ€æ±‚åˆ†æ â†’ API è®¾è®¡ â†’ å®ç° â†’ é›†æˆæµ‹è¯• â†’ éƒ¨ç½²",
            "Java é¡¹ç›®": "éœ€æ±‚åˆ†æ â†’ è®¾è®¡ â†’ ç¼–ç  â†’ æµ‹è¯• â†’ æ„å»º â†’ éƒ¨ç½²",
            "æ–‡æ¡£é¡¹ç›®": "å†…å®¹è§„åˆ’ â†’ æ’°å†™ â†’ å®¡æ ¡ â†’ å‘å¸ƒ",
            "é€šç”¨é¡¹ç›®": "éœ€æ±‚åˆ†æ â†’ è®¾è®¡ â†’ å®ç° â†’ éªŒè¯ â†’ äº¤ä»˜",
        }

        # æ ¹æ®é¡¹ç›®ç±»å‹ç”Ÿæˆç‰¹æ€§æè¿°
        feature_templates = {
            "Python é¡¹ç›®": "- åŸºäº Python å¼€å‘\n- éµå¾ª PEP 8 ä»£ç è§„èŒƒ\n- æ”¯æŒå•å…ƒæµ‹è¯•å’Œæ–‡æ¡£ç”Ÿæˆ",
            "Web é¡¹ç›®": "- ç°ä»£ Web åº”ç”¨æ¶æ„\n- ç»„ä»¶åŒ–å¼€å‘æ¨¡å¼\n- å“åº”å¼è®¾è®¡æ”¯æŒ",
            "æ•°æ®ç§‘å­¦é¡¹ç›®": "- æ•°æ®å¤„ç†ä¸åˆ†æ\n- æœºå™¨å­¦ä¹ æ¨¡å‹è®­ç»ƒ\n- å¯è§†åŒ–æŠ¥å‘Šç”Ÿæˆ",
            "Rust é¡¹ç›®": "- é«˜æ€§èƒ½ç³»ç»Ÿç¼–ç¨‹\n- å†…å­˜å®‰å…¨ä¿è¯\n- é›¶æˆæœ¬æŠ½è±¡",
            "Go é¡¹ç›®": "- ç®€æ´é«˜æ•ˆçš„è¯­æ³•\n- åŸç”Ÿå¹¶å‘æ”¯æŒ\n- å¿«é€Ÿç¼–è¯‘éƒ¨ç½²",
            "Java é¡¹ç›®": "- ä¼ä¸šçº§åº”ç”¨å¼€å‘\n- å¼ºç±»å‹ç³»ç»Ÿ\n- ä¸°å¯Œçš„ç”Ÿæ€ç³»ç»Ÿ",
            "æ–‡æ¡£é¡¹ç›®": "- ç»“æ„åŒ–æ–‡æ¡£ç®¡ç†\n- å¤šæ ¼å¼è¾“å‡ºæ”¯æŒ\n- ç‰ˆæœ¬æ§åˆ¶é›†æˆ",
            "é€šç”¨é¡¹ç›®": "- æ¨¡å—åŒ–è®¾è®¡\n- å¯æ‰©å±•æ¶æ„\n- å®Œå–„çš„æ–‡æ¡£",
        }

        # æ ¹æ®é¡¹ç›®ç±»å‹ç”Ÿæˆç¯å¢ƒè¦æ±‚
        env_templates = {
            "Python é¡¹ç›®": "- Python 3.8+\n- pip æˆ– uv åŒ…ç®¡ç†å™¨",
            "Web é¡¹ç›®": "- Node.js 18+\n- npm æˆ– pnpm åŒ…ç®¡ç†å™¨",
            "æ•°æ®ç§‘å­¦é¡¹ç›®": "- Python 3.8+\n- Jupyter Notebook\n- å¸¸ç”¨æ•°æ®ç§‘å­¦åº“",
            "Rust é¡¹ç›®": "- Rust 1.70+\n- Cargo åŒ…ç®¡ç†å™¨",
            "Go é¡¹ç›®": "- Go 1.21+\n- Go modules æ”¯æŒ",
            "Java é¡¹ç›®": "- JDK 17+\n- Maven æˆ– Gradle æ„å»ºå·¥å…·",
            "æ–‡æ¡£é¡¹ç›®": "- Markdown ç¼–è¾‘å™¨\n- é™æ€ç«™ç‚¹ç”Ÿæˆå™¨ï¼ˆå¯é€‰ï¼‰",
            "é€šç”¨é¡¹ç›®": "- æ ¹æ®é¡¹ç›®éœ€æ±‚é…ç½®",
        }

        # æ ¹æ®é¡¹ç›®ç±»å‹ç”Ÿæˆå®‰è£…æ­¥éª¤
        install_templates = {
            "Python é¡¹ç›®": "```bash\n# åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ\npython -m venv .venv\nsource .venv/bin/activate  # Windows: .venv\\Scripts\\activate\n\n# å®‰è£…ä¾èµ–\npip install -r requirements.txt\n```",
            "Web é¡¹ç›®": "```bash\n# å®‰è£…ä¾èµ–\nnpm install\n# æˆ–ä½¿ç”¨ pnpm\npnpm install\n```",
            "æ•°æ®ç§‘å­¦é¡¹ç›®": "```bash\n# åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ\npython -m venv .venv\nsource .venv/bin/activate\n\n# å®‰è£…ä¾èµ–\npip install -r requirements.txt\n```",
            "Rust é¡¹ç›®": "```bash\n# æ„å»ºé¡¹ç›®\ncargo build\n\n# è¿è¡Œæµ‹è¯•\ncargo test\n```",
            "Go é¡¹ç›®": "```bash\n# ä¸‹è½½ä¾èµ–\ngo mod download\n\n# æ„å»ºé¡¹ç›®\ngo build ./...\n```",
            "Java é¡¹ç›®": "```bash\n# Maven æ„å»º\nmvn clean install\n\n# æˆ– Gradle æ„å»º\n./gradlew build\n```",
            "æ–‡æ¡£é¡¹ç›®": "```bash\n# æ ¹æ®ä½¿ç”¨çš„æ–‡æ¡£å·¥å…·è¿›è¡Œå®‰è£…\n# ä¾‹å¦‚ MkDocs:\npip install mkdocs\nmkdocs serve\n```",
            "é€šç”¨é¡¹ç›®": "```bash\n# æ ¹æ®é¡¹ç›®éœ€æ±‚è¿›è¡Œå®‰è£…\n```",
        }

        # æ ¹æ®é¡¹ç›®ç±»å‹ç”Ÿæˆä½¿ç”¨ç¤ºä¾‹
        usage_templates = {
            "Python é¡¹ç›®": "```bash\n# è¿è¡Œä¸»ç¨‹åº\npython main.py\n\n# è¿è¡Œæµ‹è¯•\npytest\n```",
            "Web é¡¹ç›®": "```bash\n# å¼€å‘æ¨¡å¼\nnpm run dev\n\n# æ„å»ºç”Ÿäº§ç‰ˆæœ¬\nnpm run build\n```",
            "æ•°æ®ç§‘å­¦é¡¹ç›®": "```bash\n# å¯åŠ¨ Jupyter Notebook\njupyter notebook\n\n# æˆ–è¿è¡Œåˆ†æè„šæœ¬\npython analyze.py\n```",
            "Rust é¡¹ç›®": "```bash\n# è¿è¡Œé¡¹ç›®\ncargo run\n\n# å‘å¸ƒæ„å»º\ncargo build --release\n```",
            "Go é¡¹ç›®": "```bash\n# è¿è¡Œé¡¹ç›®\ngo run .\n\n# æµ‹è¯•\ngo test ./...\n```",
            "Java é¡¹ç›®": "```bash\n# Maven è¿è¡Œ\nmvn exec:java\n\n# æˆ–ç›´æ¥è¿è¡Œ JAR\njava -jar target/app.jar\n```",
            "æ–‡æ¡£é¡¹ç›®": "```bash\n# æœ¬åœ°é¢„è§ˆ\nmkdocs serve\n\n# æ„å»ºé™æ€ç«™ç‚¹\nmkdocs build\n```",
            "é€šç”¨é¡¹ç›®": "```bash\n# æ ¹æ®é¡¹ç›®éœ€æ±‚è¿è¡Œ\n```",
        }

        return {
            "é¡¹ç›®åç§°": analysis['name'],
            "é¡¹ç›®æè¿°": analysis['description'] or f"{project_type}ï¼Œéµå¾ªå·¥ç¨‹æœ€ä½³å®è·µ",
            "å·¥ä½œç›®å½•": str(output_dir),
            "é»˜è®¤è¯­è¨€": language,
            "é¡¹ç›®ç”¨é€”": analysis['description'] or f"{project_type}å¼€å‘ä¸ç»´æŠ¤",
            "æ ¸å¿ƒåŠŸèƒ½æè¿°": analysis['description'] or f"{project_type}çš„æ ¸å¿ƒåŠŸèƒ½å¼€å‘ä¸ç»´æŠ¤",
            "å·¥ä½œæµæè¿°": workflow_templates.get(project_type, workflow_templates["é€šç”¨é¡¹ç›®"]),
            "ç›®å½•æ ‘": analysis['directory_tree'],
            "é¡¹ç›®ç±»å‹": project_type,
            # README.md ä¸“ç”¨å˜é‡
            "é¡¹ç›®ç‰¹æ€§": feature_templates.get(project_type, feature_templates["é€šç”¨é¡¹ç›®"]),
            "ç¯å¢ƒè¦æ±‚": env_templates.get(project_type, env_templates["é€šç”¨é¡¹ç›®"]),
            "å®‰è£…æ­¥éª¤": install_templates.get(project_type, install_templates["é€šç”¨é¡¹ç›®"]),
            "ä½¿ç”¨ç¤ºä¾‹": usage_templates.get(project_type, usage_templates["é€šç”¨é¡¹ç›®"]),
            # CHANGELOG.md ä¸“ç”¨å˜é‡
            "ç‰ˆæœ¬å·": "1.0.0",
            "æ—¥æœŸ": today,
            "ä¸€å¥è¯æ¦‚æ‹¬é¡¹ç›®çš„ä»·å€¼ä¸»å¼ ": analysis['description'] or f"æä¾› {project_type} çš„æ ¸å¿ƒåŠŸèƒ½",
        }


def main():
    """å‘½ä»¤è¡Œå…¥å£"""
    import argparse

    parser = argparse.ArgumentParser(
        description="ä¸ºé¡¹ç›®ç”Ÿæˆ AI é¡¹ç›®æŒ‡ä»¤æ–‡ä»¶ï¼ˆCLAUDE.md + AGENTS.md + README.md + CHANGELOG.mdï¼‰",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  # å®Œå…¨è‡ªåŠ¨ç”Ÿæˆï¼ˆåˆ†æå½“å‰ç›®å½•ï¼‰
  python3 generate.py --auto

  # è‡ªåŠ¨ç”Ÿæˆå¹¶è¦†ç›–ç°æœ‰æ–‡ä»¶
  python3 generate.py --auto --overwrite

  # ä»…ç”Ÿæˆ CLAUDE.md å’Œ AGENTS.mdï¼ˆè·³è¿‡ README å’Œ CHANGELOGï¼‰
  python3 generate.py --auto --skip-readme --skip-changelog

  # ä» AGENTS.md åŒæ­¥åˆ° CLAUDE.mdï¼ˆæ¨èå·¥ä½œæµï¼‰
  python3 generate.py --sync-from agents

  # ä» CLAUDE.md åŒæ­¥åˆ° AGENTS.md
  python3 generate.py --sync-from claude

  # æ£€æŸ¥ CLAUDE.md å’Œ AGENTS.md çš„ä¸€è‡´æ€§
  python3 generate.py --check-consistency

  # åŒæ­¥åæ£€æŸ¥ä¸€è‡´æ€§
  python3 generate.py --sync-from agents && python3 generate.py --check-consistency

  # æ‰‹åŠ¨æŒ‡å®šé¡¹ç›®ä¿¡æ¯
  python3 generate.py --project-name my-project --project-description "æ•°æ®ç§‘å­¦é¡¹ç›®"

  # ä»…æ£€æµ‹è¯­è¨€
  python3 generate.py --detect-language-only
        """
    )
    parser.add_argument(
        "--auto",
        action="store_true",
        help="å®Œå…¨è‡ªåŠ¨æ¨¡å¼ï¼šåˆ†æå½“å‰ç›®å½•å¹¶ç”Ÿæˆæ–‡æ¡£"
    )
    parser.add_argument(
        "--project-name",
        help="é¡¹ç›®åç§°ï¼ˆæ‰‹åŠ¨æ¨¡å¼ï¼‰"
    )
    parser.add_argument(
        "--project-description",
        help="é¡¹ç›®æè¿°ï¼ˆæ‰‹åŠ¨æ¨¡å¼ï¼‰"
    )
    parser.add_argument(
        "--workflow",
        help="æ ¸å¿ƒå·¥ä½œæµæè¿°ï¼ˆæ‰‹åŠ¨æ¨¡å¼ï¼‰"
    )
    parser.add_argument(
        "--language",
        help="é»˜è®¤è¯­è¨€ï¼ˆç•™ç©ºåˆ™è‡ªåŠ¨æ£€æµ‹ï¼‰"
    )
    parser.add_argument(
        "--output-dir",
        default=".",
        help="è¾“å‡ºç›®å½•ï¼ˆé»˜è®¤å½“å‰ç›®å½•ï¼‰"
    )
    parser.add_argument(
        "--overwrite",
        action="store_true",
        help="è¦†ç›–å·²å­˜åœ¨çš„æ–‡ä»¶"
    )
    parser.add_argument(
        "--detect-language-only",
        action="store_true",
        help="ä»…æ£€æµ‹å¹¶æ˜¾ç¤ºè¯­è¨€"
    )
    parser.add_argument(
        "--skip-readme",
        action="store_true",
        help="è·³è¿‡ README.md ç”Ÿæˆ"
    )
    parser.add_argument(
        "--skip-changelog",
        action="store_true",
        help="è·³è¿‡ CHANGELOG.md ç”Ÿæˆ"
    )
    parser.add_argument(
        "--only-readme",
        action="store_true",
        help="ä»…ç”Ÿæˆ README.md"
    )
    parser.add_argument(
        "--only-changelog",
        action="store_true",
        help="ä»…ç”Ÿæˆ CHANGELOG.md"
    )
    parser.add_argument(
        "--sync-from",
        choices=["agents", "claude"],
        help="ä»æŒ‡å®šæ–‡ä»¶åŒæ­¥æ ¸å¿ƒç« èŠ‚åˆ°å¦ä¸€ä¸ªæ–‡ä»¶ï¼ˆagents=ä»AGENTS.mdåŒæ­¥åˆ°CLAUDE.mdï¼Œclaude=ä»CLAUDE.mdåŒæ­¥åˆ°AGENTS.mdï¼‰"
    )
    parser.add_argument(
        "--check-consistency",
        action="store_true",
        help="æ£€æŸ¥ CLAUDE.md å’Œ AGENTS.md çš„æ ¸å¿ƒç« èŠ‚æ˜¯å¦ä¸€è‡´"
    )

    args = parser.parse_args()

    # åˆ›å»ºç”Ÿæˆå™¨
    generator = ProjectInitGenerator()

    # ç¡®å®šè¾“å‡ºç›®å½•
    output_dir = Path(args.output_dir).resolve()
    claude_path = output_dir / "CLAUDE.md"
    agents_path = output_dir / "AGENTS.md"

    # æ£€æŸ¥ä¸€è‡´æ€§
    if args.check_consistency:
        if not claude_path.exists() or not agents_path.exists():
            print("âŒ CLAUDE.md å’Œ AGENTS.md å¿…é¡»éƒ½å­˜åœ¨æ‰èƒ½æ£€æŸ¥ä¸€è‡´æ€§")
            return 1

        result = generator.check_consistency(claude_path, agents_path)

        if result.get("consistent"):
            print("âœ… CLAUDE.md å’Œ AGENTS.md çš„æ ¸å¿ƒç« èŠ‚å®Œå…¨ä¸€è‡´")
            return 0
        else:
            print("âŒ CLAUDE.md å’Œ AGENTS.md çš„æ ¸å¿ƒç« èŠ‚å­˜åœ¨å·®å¼‚ï¼š\n")
            for section in result.get("diff_sections", []):
                print(f"   ğŸ“Œ {section}")
                if "details" in result and section in result["details"]:
                    details = result["details"][section]
                    print(f"      CLAUDE.md: {details.get('claude', '(ä¸å­˜åœ¨)')[:60]}...")
                    print(f"      AGENTS.md: {details.get('agents', '(ä¸å­˜åœ¨)')[:60]}...")
                    print()
            return 1

    # åŒæ­¥æ¨¡å¼
    if args.sync_from:
        if args.sync_from == "agents":
            source = agents_path
            target = claude_path
            source_name = "AGENTS.md"
            target_name = "CLAUDE.md"
        else:  # claude
            source = claude_path
            target = agents_path
            source_name = "CLAUDE.md"
            target_name = "AGENTS.md"

        if not source.exists():
            print(f"âŒ æºæ–‡ä»¶ä¸å­˜åœ¨: {source_name}")
            return 1

        if not target.exists():
            print(f"âŒ ç›®æ ‡æ–‡ä»¶ä¸å­˜åœ¨: {target_name}")
            print(f"   æç¤ºï¼šå…ˆè¿è¡Œ --auto ç”Ÿæˆä¸¤ä¸ªæ–‡ä»¶ï¼Œç„¶åå†ä½¿ç”¨åŒæ­¥åŠŸèƒ½")
            return 1

        success = generator.sync_from_source(source, target)
        return 0 if success else 1

    # ä»…æ£€æµ‹è¯­è¨€
    if args.detect_language_only:
        lang = generator.detect_language()
        print(f"æ£€æµ‹åˆ°çš„è¯­è¨€: {lang}")
        return 0

    # å®Œå…¨è‡ªåŠ¨æ¨¡å¼
    if args.auto:
        success = generator.generate_auto(
            output_dir=output_dir,
            overwrite=args.overwrite,
            skip_readme=args.skip_readme,
            skip_changelog=args.skip_changelog,
            only_readme=args.only_readme,
            only_changelog=args.only_changelog
        )
        return 0 if success else 1

    # æ‰‹åŠ¨æ¨¡å¼ï¼ˆéœ€è¦æŒ‡å®šé¡¹ç›®åç§°å’Œæè¿°ï¼‰
    if not args.project_name or not args.project_description:
        parser.error("--project-name å’Œ --project-description åœ¨æ‰‹åŠ¨æ¨¡å¼ä¸‹æ˜¯å¿…éœ€çš„ï¼ˆæˆ–ä½¿ç”¨ --auto è‡ªåŠ¨æ¨¡å¼ï¼‰")

    # æ£€æµ‹è¯­è¨€ï¼ˆé™¤éç”¨æˆ·æŒ‡å®šï¼‰
    language = args.language or generator.detect_language()

    # å‡†å¤‡å˜é‡
    variables = {
        "é¡¹ç›®åç§°": args.project_name,
        "é¡¹ç›®æè¿°": args.project_description,
        "å·¥ä½œç›®å½•": os.path.abspath(args.output_dir),
        "é»˜è®¤è¯­è¨€": language,
        "é¡¹ç›®ç”¨é€”": args.project_description,
        "æ ¸å¿ƒåŠŸèƒ½æè¿°": args.project_description,
        "å·¥ä½œæµæè¿°": args.workflow or "[å¾…è¡¥å……å·¥ä½œæµæè¿°]",
        "ç›®å½•æ ‘": "[è¯·æ ¹æ®å®é™…é¡¹ç›®ç»“æ„è¡¥å……]",
        "é¡¹ç›®ç±»å‹": "[é¡¹ç›®ç±»å‹ï¼Œå¦‚ï¼šæ•°æ®åˆ†æã€Webå¼€å‘ç­‰]",
    }

    # ç”Ÿæˆæ–‡ä»¶
    agents_content = generator.generate_agents_md(variables)
    claude_content = generator.generate_claude_md(variables)

    # å†™å…¥æ–‡ä»¶ï¼ˆä½¿ç”¨å‰é¢å®šä¹‰çš„è·¯å¾„ï¼‰
    # output_dir å’Œ claude_path/agents_path å·²ç»åœ¨å‰é¢å®šä¹‰

    success = True

    # ä½¿ç”¨æ™ºèƒ½åˆå¹¶æ¨¡å¼
    agents_was_merged = agents_path.exists() and not args.overwrite
    if not generator.write_file(agents_path, agents_content, args.overwrite, merge=True):
        print(f"é”™è¯¯: {agents_path} å·²å­˜åœ¨ï¼Œä½¿ç”¨ --overwrite è¦†ç›–")
        success = False
    elif agents_was_merged:
        print(f"ğŸ”„ {agents_path} å·²æ™ºèƒ½æ›´æ–°ï¼ˆä¿ç•™äº†è‡ªå®šä¹‰å†…å®¹ï¼‰")

    claude_was_merged = claude_path.exists() and not args.overwrite
    if not generator.write_file(claude_path, claude_content, args.overwrite, merge=True):
        print(f"é”™è¯¯: {claude_path} å·²å­˜åœ¨ï¼Œä½¿ç”¨ --overwrite è¦†ç›–")
        success = False
    elif claude_was_merged:
        print(f"ğŸ”„ {claude_path} å·²æ™ºèƒ½æ›´æ–°ï¼ˆä¿ç•™äº†è‡ªå®šä¹‰å†…å®¹ï¼‰")

    if success:
        print(f"âœ… å·²ç”Ÿæˆ:")
        print(f"   - {agents_path}")
        print(f"   - {claude_path}")
        print(f"\né»˜è®¤è¯­è¨€: {language}")
        print(f"\nè¯·æ ¹æ®å®é™…æƒ…å†µç¼–è¾‘è¿™äº›æ–‡ä»¶ï¼Œå¡«è¡¥ [å¾…è¡¥å……] çš„å†…å®¹")

    return 0 if success else 1


if __name__ == "__main__":
    sys.exit(main())
